{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c08f1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 95 light frames.\n",
      "Master Bias: shape=(2048, 2048), med=1100.000, std=7.919\n",
      "Master Dark dict: 1 exptimes -> [180.0]\n",
      "Master Flat (norm): shape=(2048, 2048), med=1.000, std=0.007\n",
      "Detected 197 stars on reference.\n",
      " processed 10/95 frames...\n",
      " processed 20/95 frames...\n",
      " processed 30/95 frames...\n",
      " processed 40/95 frames...\n",
      " processed 50/95 frames...\n",
      " processed 60/95 frames...\n",
      " processed 70/95 frames...\n",
      " processed 80/95 frames...\n",
      " processed 90/95 frames...\n",
      "Kept 197 stars after quality mask.\n",
      "Saved 189 light-curve PNGs to: ./854b_Basic_out1\\plots_allstars_lc\n",
      "Wrote CSVs: ./854b_Basic_out1\\times_jd.csv , ./854b_Basic_out1\\allstars_relflux_wide.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Full Pipeline: Calibration (bias/dark/flat) + Alignment + All-stars differential photometry\n",
    "# - Inputs:\n",
    "#     * LIGHT_DIR: raw (unaligned) light FITS\n",
    "#     * BIAS_DIR / DARK_DIR / FLAT_DIR: optional calibration frames\n",
    "# - Outputs (under OUTPUT_DIR):\n",
    "#     * aligned_fits/  : calibrated & aligned FITS (optional)\n",
    "#     * plots_allstars_lc/: per-star PNG light curves\n",
    "#     * (optional) CSVs with times/relative flux\n",
    "# - Notes:\n",
    "#     * No HOPS dependency; uses astropy, photutils, astroalign, numpy, matplotlib.\n",
    "#     * Comparison stars: 3 with similar brightness for each target star.\n",
    "# =========================================================\n",
    "\n",
    "import os, glob, math, warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from photutils.detection import DAOStarFinder\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Alignment\n",
    "import astroalign as aa\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ------------------------- User params -------------------------\n",
    "# --- I/O ---\n",
    "LIGHT_DIR   = \"./Kepler-854b/object\"   # 관측(light) 프레임 폴더\n",
    "BIAS_DIR    = \"./Kepler-854b/bias\"     # 바이어스 폴더 (없으면 None 또는 빈 폴더)\n",
    "DARK_DIR    = \"./Kepler-854b/dark\"    # 다크 폴더\n",
    "FLAT_DIR    = \"./Kepler-854b/flat\"    # 플랫 폴더\n",
    "OUTPUT_DIR  = \"./854b_Basic_out1\"           # 결과 저장 폴더\n",
    "\n",
    "# Build what you have\n",
    "USE_BIAS = True\n",
    "USE_DARK = True\n",
    "USE_FLAT = True\n",
    "\n",
    "# Alignment controls\n",
    "DO_ALIGNMENT        = True\n",
    "SAVE_ALIGNED_FITS   = True\n",
    "ALIGNED_DIR         = os.path.join(OUTPUT_DIR, \"aligned_fits\")\n",
    "\n",
    "# Photometry output\n",
    "PLOT_DIR            = os.path.join(OUTPUT_DIR, \"plots_allstars_lc\")\n",
    "SAVE_WIDE_CSV       = True\n",
    "WIDE_CSV_PATH       = os.path.join(OUTPUT_DIR, \"allstars_relflux_wide.csv\")\n",
    "TIME_CSV_PATH       = os.path.join(OUTPUT_DIR, \"times_jd.csv\")\n",
    "\n",
    "# Detection/photometry parameters\n",
    "FWHM_PIX           = 3.5\n",
    "THRESH_SIGMA       = 5.0\n",
    "MAX_STARS_DETECT   = 2000\n",
    "EDGE_MARGIN        = 12\n",
    "R_AP               = 3.0 * FWHM_PIX\n",
    "R_IN, R_OUT        = 6.0 * FWHM_PIX, 10.0 * FWHM_PIX\n",
    "K_COMPS            = 3\n",
    "BRIGHT_TOL_FRAC    = 0.30\n",
    "MIN_SEP_PIX        = 3.0 * FWHM_PIX\n",
    "CLIP_SIGMA         = 4.0\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "if SAVE_ALIGNED_FITS:\n",
    "    os.makedirs(ALIGNED_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------- Utilities -------------------------\n",
    "def list_fits_in(dirpath):\n",
    "    if not os.path.isdir(dirpath):\n",
    "        return []\n",
    "    files = sorted(glob.glob(os.path.join(dirpath, \"*.fits\")) + \n",
    "                   glob.glob(os.path.join(dirpath, \"*.fit\")))\n",
    "    return files\n",
    "\n",
    "def read_time_from_header(hdr):\n",
    "    \"\"\"Return time as JD. Try keys in priority; fall back to DATE-OBS; else NaN.\"\"\"\n",
    "    for key in [\"JD\", \"BJD\", \"HJD\"]:\n",
    "        if key in hdr:\n",
    "            try:\n",
    "                val = float(hdr[key])\n",
    "                if np.isfinite(val):\n",
    "                    return val\n",
    "            except Exception:\n",
    "                pass\n",
    "    if \"MJD\" in hdr:\n",
    "        try:\n",
    "            val = float(hdr[\"MJD\"])\n",
    "            if np.isfinite(val):\n",
    "                return val + 2400000.5\n",
    "        except Exception:\n",
    "            pass\n",
    "    if \"DATE-OBS\" in hdr:\n",
    "        for fmt in [\"isot\", None]:\n",
    "            try:\n",
    "                if fmt == \"isot\":\n",
    "                    return Time(hdr[\"DATE-OBS\"], format=\"isot\", scale=\"utc\").jd\n",
    "                else:\n",
    "                    return Time(hdr[\"DATE-OBS\"], scale=\"utc\").jd\n",
    "            except Exception:\n",
    "                continue\n",
    "    return np.nan\n",
    "\n",
    "def load_fits_data(path):\n",
    "    with fits.open(path) as hdul:\n",
    "        data = hdul[0].data.astype(float)\n",
    "        hdr  = hdul[0].header\n",
    "    return data, hdr\n",
    "\n",
    "def median_combine(files):\n",
    "    \"\"\"Median combine FITS list -> (master, header template or None).\"\"\"\n",
    "    if not files:\n",
    "        return None, None\n",
    "    stack = []\n",
    "    hdr0 = None\n",
    "    for p in files:\n",
    "        dat, hdr = load_fits_data(p)\n",
    "        if hdr0 is None:\n",
    "            hdr0 = hdr\n",
    "        stack.append(dat.astype(float))\n",
    "    master = np.nanmedian(np.stack(stack, axis=0), axis=0)\n",
    "    return master, hdr0\n",
    "\n",
    "def build_master_bias(bias_dir):\n",
    "    files = list_fits_in(bias_dir)\n",
    "    if not files:\n",
    "        return None\n",
    "    mbias, _ = median_combine(files)\n",
    "    return mbias\n",
    "\n",
    "def extract_exptime(hdr):\n",
    "    for key in [\"EXPTIME\", \"EXPOSURE\", \"EXP_TIME\"]:\n",
    "        if key in hdr:\n",
    "            try:\n",
    "                val = float(hdr[key])\n",
    "                if np.isfinite(val):\n",
    "                    return val\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "def build_master_dark_by_exptime(dark_dir):\n",
    "    \"\"\"Return dict: exptime -> master_dark (per that exptime).\"\"\"\n",
    "    files = list_fits_in(dark_dir)\n",
    "    if not files:\n",
    "        return {}\n",
    "    # group by exposure time\n",
    "    by_exp = {}\n",
    "    for p in files:\n",
    "        _, hdr = load_fits_data(p)\n",
    "        expt = extract_exptime(hdr)\n",
    "        if expt is None:\n",
    "            continue\n",
    "        by_exp.setdefault(expt, []).append(p)\n",
    "    out = {}\n",
    "    for expt, flist in by_exp.items():\n",
    "        mdark, _ = median_combine(flist)\n",
    "        out[expt] = mdark\n",
    "    return out\n",
    "\n",
    "def build_master_flat(flat_dir, master_bias=None, dark_dict=None):\n",
    "    files = list_fits_in(flat_dir)\n",
    "    if not files:\n",
    "        return None\n",
    "    cal_stack = []\n",
    "    for p in files:\n",
    "        dat, hdr = load_fits_data(p)\n",
    "        if master_bias is not None:\n",
    "            dat = dat - master_bias\n",
    "        if dark_dict is not None and len(dark_dict) > 0:\n",
    "            expt = extract_exptime(hdr)\n",
    "            if expt is not None:\n",
    "                # pick nearest dark exposure, scale by ratio\n",
    "                nearest = min(dark_dict.keys(), key=lambda k: abs(k - expt))\n",
    "                scale = expt / nearest if nearest and nearest != 0 else 1.0\n",
    "                dat = dat - dark_dict[nearest] * scale\n",
    "        cal_stack.append(dat)\n",
    "    mflat = np.nanmedian(np.stack(cal_stack, axis=0), axis=0)\n",
    "    # normalize\n",
    "    med = np.nanmedian(mflat[np.isfinite(mflat)])\n",
    "    if med and np.isfinite(med) and med != 0:\n",
    "        mflat = mflat / med\n",
    "    return mflat\n",
    "\n",
    "def calibrate_frame(data, hdr, master_bias=None, dark_dict=None, flat_norm=None):\n",
    "    \"\"\"(raw - bias - scaled dark) / flat_norm\"\"\"\n",
    "    out = data.astype(float).copy()\n",
    "    if master_bias is not None:\n",
    "        out = out - master_bias\n",
    "    if dark_dict is not None and len(dark_dict) > 0:\n",
    "        expt = extract_exptime(hdr)\n",
    "        if expt is not None:\n",
    "            nearest = min(dark_dict.keys(), key=lambda k: abs(k - expt))\n",
    "            scale = expt / nearest if nearest and nearest != 0 else 1.0\n",
    "            out = out - dark_dict[nearest] * scale\n",
    "    if flat_norm is not None:\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            out = out / flat_norm\n",
    "    return out\n",
    "\n",
    "def align_to_reference(src_img, ref_img):\n",
    "    \"\"\"Return (aligned_image, transform).\"\"\"\n",
    "    try:\n",
    "        aligned, tf = aa.register(src_img, ref_img, detection_sigma=3.0, max_control_points=50)\n",
    "        return aligned.astype(float), tf\n",
    "    except aa.MaxIterError as e:\n",
    "        raise RuntimeError(f\"Alignment failed (MaxIterError): {e}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Alignment failed: {e}\")\n",
    "\n",
    "def detect_stars(ref_img):\n",
    "    mean, med, std = sigma_clipped_stats(ref_img, sigma=3.0, maxiters=5)\n",
    "    dao = DAOStarFinder(fwhm=FWHM_PIX, threshold=THRESH_SIGMA * std)\n",
    "    tbl = dao(ref_img - med)\n",
    "    if tbl is None or len(tbl) == 0:\n",
    "        raise RuntimeError(\"No stars detected. Adjust FWHM/THRESH_SIGMA/FWHM_PIX.\")\n",
    "    tbl.sort(\"flux\")\n",
    "    tbl = tbl[::-1]\n",
    "    if len(tbl) > MAX_STARS_DETECT:\n",
    "        tbl = tbl[:MAX_STARS_DETECT]\n",
    "    xyf = np.vstack([tbl[\"xcentroid\"].data, tbl[\"ycentroid\"].data, tbl[\"flux\"].data]).T\n",
    "    H, W = ref_img.shape\n",
    "    m = (xyf[:,0] > EDGE_MARGIN) & (xyf[:,0] < W-EDGE_MARGIN) & (xyf[:,1] > EDGE_MARGIN) & (xyf[:,1] < H-EDGE_MARGIN)\n",
    "    return xyf[m]\n",
    "\n",
    "def measure_frame_photometry(img, xy):\n",
    "    apert = CircularAperture(xy, r=R_AP)\n",
    "    ann   = CircularAnnulus(xy, r_in=R_IN, r_out=R_OUT)\n",
    "    ap_masks  = apert.to_mask(method=\"exact\")\n",
    "    ann_masks = ann.to_mask(method=\"exact\")\n",
    "\n",
    "    sky_vals = []\n",
    "    for m in ann_masks:\n",
    "        ann_data = m.multiply(img)\n",
    "        mask = (ann_data == 0) | ~np.isfinite(ann_data)\n",
    "        sky_vals.append(np.nanmedian(ann_data[~mask]) if np.any(~mask) else 0.0)\n",
    "    sky_vals = np.array(sky_vals, dtype=float)\n",
    "\n",
    "    fluxes = []\n",
    "    for (m, sky) in zip(ap_masks, sky_vals):\n",
    "        ap_data = m.multiply(img)\n",
    "        mask = (ap_data == 0) | ~np.isfinite(ap_data)\n",
    "        pix = ap_data[~mask]\n",
    "        area = np.sum(~mask)\n",
    "        if area == 0:\n",
    "            fluxes.append(np.nan)\n",
    "        else:\n",
    "            fluxes.append(np.nansum(pix) - sky * area)\n",
    "    return np.array(fluxes, dtype=float)\n",
    "\n",
    "def pick_comps_for_target(target_idx, med_flux, xy, k=K_COMPS):\n",
    "    tflux = med_flux[target_idx]\n",
    "    tx, ty = xy[target_idx, 0], xy[target_idx, 1]\n",
    "    lower, upper = (1.0 - BRIGHT_TOL_FRAC) * tflux, (1.0 + BRIGHT_TOL_FRAC) * tflux\n",
    "    cand = []\n",
    "    for j in range(len(med_flux)):\n",
    "        if j == target_idx:\n",
    "            continue\n",
    "        if not np.isfinite(med_flux[j]):\n",
    "            continue\n",
    "        if (med_flux[j] >= lower) and (med_flux[j] <= upper):\n",
    "            dx = xy[j,0] - tx\n",
    "            dy = xy[j,1] - ty\n",
    "            if math.hypot(dx, dy) >= MIN_SEP_PIX:\n",
    "                cand.append((j, abs(med_flux[j] - tflux)))\n",
    "    cand.sort(key=lambda t: t[1])\n",
    "    return [c[0] for c in cand[:k]]\n",
    "\n",
    "def robust_rel_flux(target_series, comps_series):\n",
    "    denom = np.nansum(comps_series, axis=1)\n",
    "    rel = target_series / denom\n",
    "    med = np.nanmedian(rel)\n",
    "    reln = rel / med if np.isfinite(med) and med != 0 else rel\n",
    "    mu, sig = np.nanmedian(reln), np.nanstd(reln)\n",
    "    ok = np.abs(reln - mu) < CLIP_SIGMA * sig if np.isfinite(sig) and sig > 0 else np.isfinite(reln)\n",
    "    return reln, ok\n",
    "\n",
    "def plot_lightcurve(times, rel_flux, ok_mask, title, outpath, comps_ids=None):\n",
    "    t0 = np.nanmin(times)\n",
    "    xh = (times - t0) * 24.0\n",
    "    plt.figure(figsize=(7.2, 4.2))\n",
    "    plt.scatter(xh[~ok_mask], rel_flux[~ok_mask], s=14, marker='x', alpha=0.6, label=\"clipped\")\n",
    "    plt.plot(xh[ok_mask], rel_flux[ok_mask], 'o', ms=3, label=\"data\")\n",
    "    plt.xlabel(\"Time since first frame [hr]\")\n",
    "    plt.ylabel(\"Relative flux (ensemble norm.)\")\n",
    "    if comps_ids is not None:\n",
    "        sub = f\" / comps: {','.join(map(str, comps_ids))}\"\n",
    "    else:\n",
    "        sub = \"\"\n",
    "    plt.title(f\"{title}{sub}\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "# ------------------------- Pipeline -------------------------\n",
    "def main():\n",
    "    # 0) Gather raw lights\n",
    "    light_files = list_fits_in(LIGHT_DIR)\n",
    "    if not light_files:\n",
    "        raise FileNotFoundError(f\"No light frames in {LIGHT_DIR}\")\n",
    "    print(f\"Found {len(light_files)} light frames.\")\n",
    "\n",
    "    # 1) Build masters\n",
    "    mbias = build_master_bias(BIAS_DIR) if USE_BIAS else None\n",
    "    dark_dict = build_master_dark_by_exptime(DARK_DIR) if USE_DARK else {}\n",
    "    mflat = build_master_flat(FLAT_DIR, master_bias=mbias, dark_dict=dark_dict) if USE_FLAT else None\n",
    "\n",
    "    def _brief(name, arr):\n",
    "        if arr is None or (isinstance(arr, dict) and len(arr)==0):\n",
    "            return f\"{name}: None\"\n",
    "        if isinstance(arr, dict):\n",
    "            keys = sorted(list(arr.keys()))\n",
    "            return f\"{name}: {len(keys)} exptimes -> {keys[:5]}{'...' if len(keys)>5 else ''}\"\n",
    "        return f\"{name}: shape={arr.shape}, med={np.nanmedian(arr):.3f}, std={np.nanstd(arr):.3f}\"\n",
    "\n",
    "    print(_brief(\"Master Bias\", mbias))\n",
    "    print(_brief(\"Master Dark dict\", dark_dict))\n",
    "    print(_brief(\"Master Flat (norm)\", mflat))\n",
    "\n",
    "    # 2) Calibrate & align (streaming)\n",
    "    ref_data_raw, ref_hdr = load_fits_data(light_files[0])\n",
    "    ref_cal = calibrate_frame(ref_data_raw, ref_hdr, master_bias=mbias, dark_dict=dark_dict, flat_norm=mflat)\n",
    "\n",
    "    if DO_ALIGNMENT:\n",
    "        ref_img = ref_cal\n",
    "    else:\n",
    "        ref_img = ref_cal  # still use calibrated first frame as reference\n",
    "\n",
    "    if SAVE_ALIGNED_FITS:\n",
    "        h = ref_hdr.copy()\n",
    "        h[\"HISTORY\"] = \"calibrated; reference frame; aligned identity\"\n",
    "        fits.writeto(os.path.join(ALIGNED_DIR, os.path.basename(light_files[0])), ref_img.astype(np.float32), h, overwrite=True)\n",
    "\n",
    "    # 3) Detect stars on reference\n",
    "    xyf = detect_stars(ref_img)\n",
    "    xy  = xyf[:, :2]\n",
    "    print(f\"Detected {len(xy)} stars on reference.\")\n",
    "\n",
    "    # 4) For each frame: calibrate -> align -> photometry\n",
    "    times = []\n",
    "    rows = []  # list of flux arrays length M\n",
    "    skipped = 0\n",
    "\n",
    "    for idx, p in enumerate(light_files):\n",
    "        data, hdr = load_fits_data(p)\n",
    "        cal = calibrate_frame(data, hdr, master_bias=mbias, dark_dict=dark_dict, flat_norm=mflat)\n",
    "\n",
    "        if DO_ALIGNMENT and idx > 0:\n",
    "            try:\n",
    "                aligned, tf = align_to_reference(cal, ref_img)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Align failed at {os.path.basename(p)}: {e}\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "        else:\n",
    "            aligned = cal\n",
    "\n",
    "        # time\n",
    "        t_jd = read_time_from_header(hdr)\n",
    "        if not np.isfinite(t_jd):\n",
    "            t_jd = np.nan  # will fix later with index fallback\n",
    "        times.append(t_jd)\n",
    "\n",
    "        # photometry\n",
    "        fluxes = measure_frame_photometry(aligned, xy)  # length M\n",
    "        rows.append(fluxes)\n",
    "\n",
    "        # save aligned fits\n",
    "        if SAVE_ALIGNED_FITS:\n",
    "            h = hdr.copy()\n",
    "            h[\"HISTORY\"] = \"calibrated & aligned\"\n",
    "            fits.writeto(os.path.join(ALIGNED_DIR, os.path.basename(p)), aligned.astype(np.float32), h, overwrite=True)\n",
    "\n",
    "        if (idx+1) % 10 == 0:\n",
    "            print(f\" processed {idx+1}/{len(light_files)} frames...\")\n",
    "\n",
    "    if skipped > 0:\n",
    "        print(f\"Alignment skipped {skipped} frames due to errors.\")\n",
    "\n",
    "    # 5) Assemble flux matrix and times\n",
    "    flux_mat = np.vstack(rows)   # (N_valid, M)\n",
    "    times = np.array(times, dtype=float)\n",
    "    if np.any(~np.isfinite(times)):\n",
    "        # replace NaN times with indices\n",
    "        times = np.arange(len(times), dtype=float)\n",
    "\n",
    "    # quality filter on stars\n",
    "    valid_ratio = np.mean(np.isfinite(flux_mat), axis=0)\n",
    "    keep = valid_ratio > 0.5\n",
    "    xy, flux_mat = xy[keep], flux_mat[:, keep]\n",
    "    print(f\"Kept {xy.shape[0]} stars after quality mask.\")\n",
    "\n",
    "    # 6) Build relative flux per star using 3 comps each + PNGs\n",
    "    med_flux = np.nanmedian(flux_mat, axis=0)\n",
    "    saved = 0\n",
    "    rel_wide = {}  # star_i -> rel_flux array\n",
    "\n",
    "    for ti in range(xy.shape[0]):\n",
    "        comp_ids = pick_comps_for_target(ti, med_flux, xy, k=K_COMPS)\n",
    "        if len(comp_ids) < K_COMPS:\n",
    "            continue\n",
    "        target_series = flux_mat[:, ti]\n",
    "        comps_series  = flux_mat[:, comp_ids]    # (N, K)\n",
    "        rel, ok = robust_rel_flux(target_series, comps_series)\n",
    "\n",
    "        # save PNG\n",
    "        outpng = os.path.join(PLOT_DIR, f\"lc_star{ti:04d}.png\")\n",
    "        title  = f\"Star {ti:04d} @ (x={xy[ti,0]:.1f}, y={xy[ti,1]:.1f})\"\n",
    "        plot_lightcurve(times, rel, ok, title, outpng, comps_ids=[int(i) for i in comp_ids])\n",
    "        rel_wide[f\"star{ti:04d}\"] = rel\n",
    "        saved += 1\n",
    "\n",
    "    print(f\"Saved {saved} light-curve PNGs to: {PLOT_DIR}\")\n",
    "\n",
    "    # 7) Optional CSVs\n",
    "    if SAVE_WIDE_CSV and saved > 0:\n",
    "        # times\n",
    "        pd.DataFrame({\"JD\": times}).to_csv(TIME_CSV_PATH, index=False)\n",
    "        # rel flux wide\n",
    "        wide = pd.DataFrame(rel_wide)\n",
    "        wide.insert(0, \"JD\", times)\n",
    "        wide.to_csv(WIDE_CSV_PATH, index=False)\n",
    "        print(f\"Wrote CSVs: {TIME_CSV_PATH} , {WIDE_CSV_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73315c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 95 light frames.\n",
      "Detected 197 stars on reference.\n",
      "Preview saved: ./854b_Basic_out2\\detected_stars_preview.png\n",
      " processed 10/95 frames...\n",
      " processed 20/95 frames...\n",
      " processed 30/95 frames...\n",
      " processed 40/95 frames...\n",
      " processed 50/95 frames...\n",
      " processed 60/95 frames...\n",
      " processed 70/95 frames...\n",
      " processed 80/95 frames...\n",
      " processed 90/95 frames...\n",
      "Kept 197 stars after quality mask.\n",
      "Saved 189 light-curve PNGs to: ./854b_Basic_out2\\plots_allstars_lc\n",
      "Wrote CSVs: ./854b_Basic_out2\\times_jd.csv , ./854b_Basic_out2\\allstars_relflux_wide.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Full Pipeline (Calib + Align + Photometry) with \"detected stars\" annotated preview\n",
    "# =========================================================\n",
    "\n",
    "import os, glob, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "\n",
    "from photutils.detection import DAOStarFinder\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus\n",
    "\n",
    "import astroalign as aa\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ------------------------- User params -------------------------\n",
    "LIGHT_DIR   = \"./Kepler-854b/object\"   # 관측(light) 프레임 폴더\n",
    "BIAS_DIR    = \"./Kepler-854b/bias\"     # 바이어스 폴더 (없으면 None 또는 빈 폴더)\n",
    "DARK_DIR    = \"./Kepler-854b/dark\"    # 다크 폴더\n",
    "FLAT_DIR    = \"./Kepler-854b/flat\"    # 플랫 폴더\n",
    "OUTPUT_DIR  = \"./854b_Basic_out2\"           # 결과 저장 폴더\n",
    "\n",
    "USE_BIAS = True\n",
    "USE_DARK = True\n",
    "USE_FLAT = True\n",
    "\n",
    "DO_ALIGNMENT        = True\n",
    "SAVE_ALIGNED_FITS   = True\n",
    "ALIGNED_DIR         = os.path.join(OUTPUT_DIR, \"aligned_fits\")\n",
    "\n",
    "PLOT_DIR            = os.path.join(OUTPUT_DIR, \"plots_allstars_lc\")\n",
    "SAVE_WIDE_CSV       = True\n",
    "WIDE_CSV_PATH       = os.path.join(OUTPUT_DIR, \"allstars_relflux_wide.csv\")\n",
    "TIME_CSV_PATH       = os.path.join(OUTPUT_DIR, \"times_jd.csv\")\n",
    "\n",
    "# Detection/photometry parameters\n",
    "FWHM_PIX           = 3.5\n",
    "THRESH_SIGMA       = 5.0\n",
    "MAX_STARS_DETECT   = 2000\n",
    "EDGE_MARGIN        = 12\n",
    "R_AP               = 3.0 * FWHM_PIX\n",
    "R_IN, R_OUT        = 6.0 * FWHM_PIX, 10.0 * FWHM_PIX\n",
    "K_COMPS            = 3\n",
    "BRIGHT_TOL_FRAC    = 0.30\n",
    "MIN_SEP_PIX        = 3.0 * FWHM_PIX\n",
    "CLIP_SIGMA         = 4.0\n",
    "\n",
    "# Preview rendering\n",
    "N_LABELS_PREVIEW   = 100   # annotate first N stars (brightest first)\n",
    "PREVIEW_PATH       = os.path.join(OUTPUT_DIR, \"detected_stars_preview.png\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "if SAVE_ALIGNED_FITS:\n",
    "    os.makedirs(ALIGNED_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------- Utilities -------------------------\n",
    "def list_fits_in(dirpath):\n",
    "    if not os.path.isdir(dirpath):\n",
    "        return []\n",
    "    files = sorted(glob.glob(os.path.join(dirpath, \"*.fits\")) + \n",
    "                   glob.glob(os.path.join(dirpath, \"*.fit\")))\n",
    "    return files\n",
    "\n",
    "def read_time_from_header(hdr):\n",
    "    for key in [\"JD\", \"BJD\", \"HJD\"]:\n",
    "        if key in hdr:\n",
    "            try:\n",
    "                val = float(hdr[key])\n",
    "                if np.isfinite(val):\n",
    "                    return val\n",
    "            except Exception:\n",
    "                pass\n",
    "    if \"MJD\" in hdr:\n",
    "        try:\n",
    "            val = float(hdr[\"MJD\"])\n",
    "            if np.isfinite(val):\n",
    "                return val + 2400000.5\n",
    "        except Exception:\n",
    "            pass\n",
    "    if \"DATE-OBS\" in hdr:\n",
    "        for fmt in [\"isot\", None]:\n",
    "            try:\n",
    "                if fmt == \"isot\":\n",
    "                    return Time(hdr[\"DATE-OBS\"], format=\"isot\", scale=\"utc\").jd\n",
    "                else:\n",
    "                    return Time(hdr[\"DATE-OBS\"], scale=\"utc\").jd\n",
    "            except Exception:\n",
    "                continue\n",
    "    return np.nan\n",
    "\n",
    "def load_fits_data(path):\n",
    "    with fits.open(path) as hdul:\n",
    "        data = hdul[0].data.astype(float)\n",
    "        hdr  = hdul[0].header\n",
    "    return data, hdr\n",
    "\n",
    "def median_combine(files):\n",
    "    if not files:\n",
    "        return None, None\n",
    "    stack = []\n",
    "    hdr0 = None\n",
    "    for p in files:\n",
    "        dat, hdr = load_fits_data(p)\n",
    "        if hdr0 is None:\n",
    "            hdr0 = hdr\n",
    "        stack.append(dat.astype(float))\n",
    "    master = np.nanmedian(np.stack(stack, axis=0), axis=0)\n",
    "    return master, hdr0\n",
    "\n",
    "def build_master_bias(bias_dir):\n",
    "    files = list_fits_in(bias_dir)\n",
    "    if not files:\n",
    "        return None\n",
    "    mbias, _ = median_combine(files)\n",
    "    return mbias\n",
    "\n",
    "def extract_exptime(hdr):\n",
    "    for key in [\"EXPTIME\", \"EXPOSURE\", \"EXP_TIME\"]:\n",
    "        if key in hdr:\n",
    "            try:\n",
    "                val = float(hdr[key])\n",
    "                if np.isfinite(val):\n",
    "                    return val\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "def build_master_dark_by_exptime(dark_dir):\n",
    "    files = list_fits_in(dark_dir)\n",
    "    if not files:\n",
    "        return {}\n",
    "    by_exp = {}\n",
    "    for p in files:\n",
    "        _, hdr = load_fits_data(p)\n",
    "        expt = extract_exptime(hdr)\n",
    "        if expt is None:\n",
    "            continue\n",
    "        by_exp.setdefault(expt, []).append(p)\n",
    "    out = {}\n",
    "    for expt, flist in by_exp.items():\n",
    "        mdark, _ = median_combine(flist)\n",
    "        out[expt] = mdark\n",
    "    return out\n",
    "\n",
    "def build_master_flat(flat_dir, master_bias=None, dark_dict=None):\n",
    "    files = list_fits_in(flat_dir)\n",
    "    if not files:\n",
    "        return None\n",
    "    cal_stack = []\n",
    "    for p in files:\n",
    "        dat, hdr = load_fits_data(p)\n",
    "        if master_bias is not None:\n",
    "            dat = dat - master_bias\n",
    "        if dark_dict is not None and len(dark_dict) > 0:\n",
    "            expt = extract_exptime(hdr)\n",
    "            if expt is not None:\n",
    "                nearest = min(dark_dict.keys(), key=lambda k: abs(k - expt))\n",
    "                scale = expt / nearest if nearest and nearest != 0 else 1.0\n",
    "                dat = dat - dark_dict[nearest] * scale\n",
    "        cal_stack.append(dat)\n",
    "    mflat = np.nanmedian(np.stack(cal_stack, axis=0), axis=0)\n",
    "    med = np.nanmedian(mflat[np.isfinite(mflat)])\n",
    "    if med and np.isfinite(med) and med != 0:\n",
    "        mflat = mflat / med\n",
    "    return mflat\n",
    "\n",
    "def calibrate_frame(data, hdr, master_bias=None, dark_dict=None, flat_norm=None):\n",
    "    out = data.astype(float).copy()\n",
    "    if master_bias is not None:\n",
    "        out = out - master_bias\n",
    "    if dark_dict is not None and len(dark_dict) > 0:\n",
    "        expt = extract_exptime(hdr)\n",
    "        if expt is not None:\n",
    "            nearest = min(dark_dict.keys(), key=lambda k: abs(k - expt))\n",
    "            scale = expt / nearest if nearest and nearest != 0 else 1.0\n",
    "            out = out - dark_dict[nearest] * scale\n",
    "    if flat_norm is not None:\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            out = out / flat_norm\n",
    "    return out\n",
    "\n",
    "def align_to_reference(src_img, ref_img):\n",
    "    try:\n",
    "        aligned, tf = aa.register(src_img, ref_img, detection_sigma=3.0, max_control_points=50)\n",
    "        return aligned.astype(float), tf\n",
    "    except aa.MaxIterError as e:\n",
    "        raise RuntimeError(f\"Alignment failed (MaxIterError): {e}\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Alignment failed: {e}\")\n",
    "\n",
    "def detect_stars(ref_img):\n",
    "    mean, med, std = sigma_clipped_stats(ref_img, sigma=3.0, maxiters=5)\n",
    "    dao = DAOStarFinder(fwhm=FWHM_PIX, threshold=THRESH_SIGMA * std)\n",
    "    tbl = dao(ref_img - med)\n",
    "    if tbl is None or len(tbl) == 0:\n",
    "        raise RuntimeError(\"No stars detected. Adjust FWHM/THRESH_SIGMA/FWHM_PIX.\")\n",
    "    tbl.sort(\"flux\")\n",
    "    tbl = tbl[::-1]\n",
    "    if len(tbl) > MAX_STARS_DETECT:\n",
    "        tbl = tbl[:MAX_STARS_DETECT]\n",
    "    xyf = np.vstack([tbl[\"xcentroid\"].data, tbl[\"ycentroid\"].data, tbl[\"flux\"].data]).T\n",
    "    H, W = ref_img.shape\n",
    "    m = (xyf[:,0] > EDGE_MARGIN) & (xyf[:,0] < W-EDGE_MARGIN) & (xyf[:,1] > EDGE_MARGIN) & (xyf[:,1] < H-EDGE_MARGIN)\n",
    "    return xyf[m]\n",
    "\n",
    "def measure_frame_photometry(img, xy):\n",
    "    apert = CircularAperture(xy, r=R_AP)\n",
    "    ann   = CircularAnnulus(xy, r_in=R_IN, r_out=R_OUT)\n",
    "    ap_masks  = apert.to_mask(method=\"exact\")\n",
    "    ann_masks = ann.to_mask(method=\"exact\")\n",
    "\n",
    "    sky_vals = []\n",
    "    for m in ann_masks:\n",
    "        ann_data = m.multiply(img)\n",
    "        mask = (ann_data == 0) | ~np.isfinite(ann_data)\n",
    "        sky_vals.append(np.nanmedian(ann_data[~mask]) if np.any(~mask) else 0.0)\n",
    "    sky_vals = np.array(sky_vals, dtype=float)\n",
    "\n",
    "    fluxes = []\n",
    "    for (m, sky) in zip(ap_masks, sky_vals):\n",
    "        ap_data = m.multiply(img)\n",
    "        mask = (ap_data == 0) | ~np.isfinite(ap_data)\n",
    "        pix = ap_data[~mask]\n",
    "        area = np.sum(~mask)\n",
    "        if area == 0:\n",
    "            fluxes.append(np.nan)\n",
    "        else:\n",
    "            fluxes.append(np.nansum(pix) - sky * area)\n",
    "    return np.array(fluxes, dtype=float)\n",
    "\n",
    "def pick_comps_for_target(target_idx, med_flux, xy, k=K_COMPS):\n",
    "    tflux = med_flux[target_idx]\n",
    "    tx, ty = xy[target_idx, 0], xy[target_idx, 1]\n",
    "    lower, upper = (1.0 - BRIGHT_TOL_FRAC) * tflux, (1.0 + BRIGHT_TOL_FRAC) * tflux\n",
    "    cand = []\n",
    "    for j in range(len(med_flux)):\n",
    "        if j == target_idx:\n",
    "            continue\n",
    "        if not np.isfinite(med_flux[j]):\n",
    "            continue\n",
    "        if (med_flux[j] >= lower) and (med_flux[j] <= upper):\n",
    "            dx = xy[j,0] - tx\n",
    "            dy = xy[j,1] - ty\n",
    "            if math.hypot(dx, dy) >= MIN_SEP_PIX:\n",
    "                cand.append((j, abs(med_flux[j] - tflux)))\n",
    "    cand.sort(key=lambda t: t[1])\n",
    "    return [c[0] for c in cand[:k]]\n",
    "\n",
    "def robust_rel_flux(target_series, comps_series):\n",
    "    denom = np.nansum(comps_series, axis=1)\n",
    "    rel = target_series / denom\n",
    "    med = np.nanmedian(rel)\n",
    "    reln = rel / med if np.isfinite(med) and med != 0 else rel\n",
    "    mu, sig = np.nanmedian(reln), np.nanstd(reln)\n",
    "    ok = np.abs(reln - mu) < CLIP_SIGMA * sig if np.isfinite(sig) and sig > 0 else np.isfinite(reln)\n",
    "    return reln, ok\n",
    "\n",
    "def _stretch(img, p_lo=1, p_hi=99):\n",
    "    \"\"\"Percentile stretch for nicer preview.\"\"\"\n",
    "    finite = np.isfinite(img)\n",
    "    if not np.any(finite):\n",
    "        return img\n",
    "    v1, v2 = np.percentile(img[finite], [p_lo, p_hi])\n",
    "    v1, v2 = float(v1), float(v2)\n",
    "    out = np.clip((img - v1) / max(v2 - v1, 1e-9), 0, 1)\n",
    "    return out\n",
    "\n",
    "def save_detection_preview(ref_img, xy, path=PREVIEW_PATH, n_labels=N_LABELS_PREVIEW):\n",
    "    \"\"\"Save a single image: background = ref_img, overlay = aperture/annulus + star indices.\"\"\"\n",
    "    disp = _stretch(ref_img)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(disp, cmap=\"gray\", origin=\"lower\")\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label(\"stretched intensity\")\n",
    "\n",
    "    # draw rings for first n_labels (or all, if smaller)\n",
    "    n = min(n_labels, xy.shape[0])\n",
    "    # Aperture & annulus objects for plotting\n",
    "    apert = CircularAperture(xy[:n], r=R_AP)\n",
    "    ann   = CircularAnnulus(xy[:n], r_in=R_IN, r_out=R_OUT)\n",
    "    try:\n",
    "        apert.plot(ax=ax, lw=1.2, color=\"cyan\")\n",
    "        ann.plot(ax=ax, lw=1.0, color=\"lime\")\n",
    "    except Exception:\n",
    "        # fallback: just draw apertures if annulus plotting fails\n",
    "        apert.plot(ax=ax, lw=1.2, color=\"cyan\")\n",
    "\n",
    "    # labels\n",
    "    for i in range(n):\n",
    "        x, y = xy[i]\n",
    "        ax.text(x+5, y+5, f\"{i}\", color=\"yellow\", fontsize=9, weight=\"bold\", ha=\"left\", va=\"bottom\")\n",
    "\n",
    "    ax.set_title(f\"Detected stars (N={xy.shape[0]}), aperture/annulus rings\")\n",
    "    ax.set_xlim(0, ref_img.shape[1])\n",
    "    ax.set_ylim(0, ref_img.shape[0])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=160)\n",
    "    plt.close()\n",
    "    return path\n",
    "\n",
    "def plot_lightcurve(times, rel_flux, ok_mask, title, outpath, comps_ids=None):\n",
    "    t0 = np.nanmin(times)\n",
    "    xh = (times - t0) * 24.0\n",
    "    plt.figure(figsize=(7.2, 4.2))\n",
    "    plt.scatter(xh[~ok_mask], rel_flux[~ok_mask], s=14, marker='x', alpha=0.6, label=\"clipped\")\n",
    "    plt.plot(xh[ok_mask], rel_flux[ok_mask], 'o', ms=3, label=\"data\")\n",
    "    plt.xlabel(\"Time since first frame [hr]\")\n",
    "    plt.ylabel(\"Relative flux (ensemble norm.)\")\n",
    "    if comps_ids is not None:\n",
    "        sub = f\" / comps: {','.join(map(str, comps_ids))}\"\n",
    "    else:\n",
    "        sub = \"\"\n",
    "    plt.title(f\"{title}{sub}\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "# ------------------------- Pipeline -------------------------\n",
    "def main():\n",
    "    light_files = list_fits_in(LIGHT_DIR)\n",
    "    if not light_files:\n",
    "        raise FileNotFoundError(f\"No light frames in {LIGHT_DIR}\")\n",
    "    print(f\"Found {len(light_files)} light frames.\")\n",
    "\n",
    "    # 1) Masters\n",
    "    mbias = build_master_bias(BIAS_DIR) if USE_BIAS else None\n",
    "    dark_dict = build_master_dark_by_exptime(DARK_DIR) if USE_DARK else {}\n",
    "    mflat = build_master_flat(FLAT_DIR, master_bias=mbias, dark_dict=dark_dict) if USE_FLAT else None\n",
    "\n",
    "    # 2) Calibrate first as reference\n",
    "    ref_raw, ref_hdr = load_fits_data(light_files[0])\n",
    "    ref_cal = calibrate_frame(ref_raw, ref_hdr, master_bias=mbias, dark_dict=dark_dict, flat_norm=mflat)\n",
    "    ref_img = ref_cal\n",
    "\n",
    "    if SAVE_ALIGNED_FITS:\n",
    "        h = ref_hdr.copy()\n",
    "        h[\"HISTORY\"] = \"calibrated; reference frame; aligned identity\"\n",
    "        fits.writeto(os.path.join(ALIGNED_DIR, os.path.basename(light_files[0])),\n",
    "                     ref_img.astype(np.float32), h, overwrite=True)\n",
    "\n",
    "    # 3) Detect stars & save annotated preview\n",
    "    xyf = detect_stars(ref_img)\n",
    "    xy  = xyf[:, :2]\n",
    "    print(f\"Detected {len(xy)} stars on reference.\")\n",
    "    prev_path = save_detection_preview(ref_img, xy, PREVIEW_PATH, N_LABELS_PREVIEW)\n",
    "    print(f\"Preview saved: {prev_path}\")\n",
    "\n",
    "    # 4) Iterate frames: calibrate, align (to ref), photometry\n",
    "    times = []\n",
    "    rows = []\n",
    "    skipped = 0\n",
    "\n",
    "    for idx, p in enumerate(light_files):\n",
    "        data, hdr = load_fits_data(p)\n",
    "        cal = calibrate_frame(data, hdr, master_bias=mbias, dark_dict=dark_dict, flat_norm=mflat)\n",
    "\n",
    "        if DO_ALIGNMENT and idx > 0:\n",
    "            try:\n",
    "                aligned, tf = align_to_reference(cal, ref_img)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Align failed at {os.path.basename(p)}: {e}\")\n",
    "                skipped += 1\n",
    "                continue\n",
    "        else:\n",
    "            aligned = cal\n",
    "\n",
    "        t_jd = read_time_from_header(hdr)\n",
    "        if not np.isfinite(t_jd):\n",
    "            t_jd = np.nan\n",
    "        times.append(t_jd)\n",
    "\n",
    "        fluxes = measure_frame_photometry(aligned, xy)  # length M\n",
    "        rows.append(fluxes)\n",
    "\n",
    "        if SAVE_ALIGNED_FITS:\n",
    "            h = hdr.copy()\n",
    "            h[\"HISTORY\"] = \"calibrated & aligned\"\n",
    "            fits.writeto(os.path.join(ALIGNED_DIR, os.path.basename(p)),\n",
    "                         aligned.astype(np.float32), h, overwrite=True)\n",
    "\n",
    "        if (idx+1) % 10 == 0:\n",
    "            print(f\" processed {idx+1}/{len(light_files)} frames...\")\n",
    "\n",
    "    if skipped > 0:\n",
    "        print(f\"Alignment skipped {skipped} frames due to errors.\")\n",
    "\n",
    "    flux_mat = np.vstack(rows)\n",
    "    times = np.array(times, dtype=float)\n",
    "    if np.any(~np.isfinite(times)):\n",
    "        times = np.arange(len(times), dtype=float)\n",
    "\n",
    "    # Filter stars\n",
    "    valid_ratio = np.mean(np.isfinite(flux_mat), axis=0)\n",
    "    keep = valid_ratio > 0.5\n",
    "    xy, flux_mat = xy[keep], flux_mat[:, keep]\n",
    "    print(f\"Kept {xy.shape[0]} stars after quality mask.\")\n",
    "\n",
    "    # Build relative flux and PNGs\n",
    "    med_flux = np.nanmedian(flux_mat, axis=0)\n",
    "    saved = 0\n",
    "    rel_wide = {}\n",
    "\n",
    "    for ti in range(xy.shape[0]):\n",
    "        comp_ids = pick_comps_for_target(ti, med_flux, xy, k=K_COMPS)\n",
    "        if len(comp_ids) < K_COMPS:\n",
    "            continue\n",
    "        target_series = flux_mat[:, ti]\n",
    "        comps_series  = flux_mat[:, comp_ids]\n",
    "        rel, ok = robust_rel_flux(target_series, comps_series)\n",
    "\n",
    "        outpng = os.path.join(PLOT_DIR, f\"lc_star{ti:04d}.png\")\n",
    "        title  = f\"Star {ti:04d} @ (x={xy[ti,0]:.1f}, y={xy[ti,1]:.1f})\"\n",
    "        plot_lightcurve(times, rel, ok, title, outpng, comps_ids=[int(i) for i in comp_ids])\n",
    "        rel_wide[f\"star{ti:04d}\"] = rel\n",
    "        saved += 1\n",
    "\n",
    "    print(f\"Saved {saved} light-curve PNGs to: {PLOT_DIR}\")\n",
    "\n",
    "    if SAVE_WIDE_CSV and saved > 0:\n",
    "        pd.DataFrame({\"JD\": times}).to_csv(TIME_CSV_PATH, index=False)\n",
    "        wide = pd.DataFrame(rel_wide)\n",
    "        wide.insert(0, \"JD\", times)\n",
    "        wide.to_csv(WIDE_CSV_PATH, index=False)\n",
    "        print(f\"Wrote CSVs: {TIME_CSV_PATH} , {WIDE_CSV_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NASAAPP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
